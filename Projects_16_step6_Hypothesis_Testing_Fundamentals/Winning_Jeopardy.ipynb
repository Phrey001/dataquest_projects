{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553010d6-3b00-44cc-9f78-92b32f4a6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from IPython.display import Image  # for displaying images in markdown cells\n",
    "import pandas as pd  # Dataframe manipulation\n",
    "import numpy as np  # Arrays manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b2c934-be07-4d8c-a120-ea4aba861bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {align:left;display:block}  # to align html tables to left\n",
       "</style> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {align:left;display:block}  # to align html tables to left\n",
    "</style> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11755744-7945-4aff-9d2f-170c6aae808e",
   "metadata": {},
   "source": [
    "# Dataquest | Hypothesis Testing: Fundamentals <br/> <br/> Project Title: Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de734fd-d504-4d61-a690-598570d398fc",
   "metadata": {},
   "source": [
    "## 1) Introduction / Jeopardy Questions\n",
    "\n",
    "#### Background:\n",
    "\n",
    "Provided by: [Dataquest.io](https://www.dataquest.io/)\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture.\n",
    "\n",
    "Imagine that you want to compete on Jeopardy, and you're looking for any way to win. In this project, you'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset is named **jeopardy.csv**, and contains **20000** rows from the beginning of a full dataset of Jeopardy questions, which you can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/).\n",
    "\n",
    "As you can see, each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "Columns | Description\n",
    "--- | ---\n",
    "Show Number | the Jeopardy episode number\n",
    "Air Date | the date the episode aired\n",
    "Round | the round of Jeopardy\n",
    "Category | the category of the question\n",
    "Value | the number of dollars the correct answer is worth\n",
    "Question | the text of the question\n",
    "Answer | the text of the answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9207ee5b-aab9-426c-a4ea-5ffb37f71892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file into dataframe\n",
    "df = pd.read_csv('JEOPARDY_CSV.csv')\n",
    "\n",
    "# review file\n",
    "print(df.columns,'\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f955d76-93d1-421b-b662-eb2d70b05cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove the spaces from columns\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# review transformation\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a81077-1c56-4e8e-b12b-6ffa17104cc4",
   "metadata": {},
   "source": [
    "## 2) Normalising Text\n",
    "\n",
    "Provided by: [Dataquest.io](https://www.dataquest.io/)\n",
    "\n",
    "Before starting analysis on the Jeopardy questions, need to normalize all of the text columns (the **Question** and **Answer** columns).\n",
    "\n",
    "The idea is to put words in lowercase and remove punctuation for comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f6d302-5b1d-4549-85d1-67431d532686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to normalize questions and answers.\n",
    "\n",
    "import re  # to work with regex\n",
    "\n",
    "def normalise_string(sentence):\n",
    "    sentence_new = str(sentence).lower()\n",
    "    sentence_new = re.sub(r'[^A-Za-z0-9_\\s]', '', sentence_new, flags=re.I)\n",
    "    return sentence_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2ac01f-7bbb-40d6-9cfe-3d789a327a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the last 8 years of his life galileo was under house arrest for espousing this mans theory \n",
      "\n",
      "For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    for the last 8 years of his life galileo was u...\n",
       "1    no 2 1912 olympian football star at carlisle i...\n",
       "2    the city of yuma in this state has a record av...\n",
       "3    in 1963 live on the art linkletter show this c...\n",
       "4    signer of the dec of indep framer of the const...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the 'Question' column.\n",
    "df['clean_question'] = df['Question'].apply(normalise_string)\n",
    "\n",
    "# review transformation\n",
    "print(df['clean_question'][0], '\\n')\n",
    "print(df['Question'][0], '\\n')\n",
    "df['clean_question'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e065dd3-8e39-4cca-9fef-c9c75accd282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copernicus \n",
      "\n",
      "Copernicus \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    copernicus\n",
       "1    jim thorpe\n",
       "2       arizona\n",
       "3     mcdonalds\n",
       "4    john adams\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the 'Answer' column.\n",
    "df['clean_answer'] = df['Answer'].apply(normalise_string)\n",
    "\n",
    "# review transformation\n",
    "print(df['clean_answer'][0], '\\n')\n",
    "print(df['Answer'][0], '\\n')\n",
    "df['clean_answer'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c741f-b25d-490d-9e89-17b9951d734e",
   "metadata": {},
   "source": [
    "## 3) Normalising Columns\n",
    "\n",
    "Provided by: [Dataquest.io](https://www.dataquest.io/)\n",
    "\n",
    "There are also some other columns to normalise.\n",
    "\n",
    "The **Value** column should be numeric, to allow easier manipulation. Need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "\n",
    "The **Air Date** column should also be a datetime, not a string, to enable to work it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f7499e-fb2d-4947-ad02-5132d662a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$200 \n",
      "\n",
      "200 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400      42244\n",
       "800      31860\n",
       "200      30455\n",
       "1000     21640\n",
       "600      20377\n",
       "         ...  \n",
       "9800         1\n",
       "16400        1\n",
       "9500         1\n",
       "585          1\n",
       "1407         1\n",
       "Name: clean_value, Length: 146, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function to normalize dollar values.\n",
    "# Also assign 0 instead if the conversion has an error.\n",
    "\n",
    "def normalise_value(value):\n",
    "    try:\n",
    "        value_new = re.sub(r'[^A-Za-z0-9_\\s]', '', str(value))\n",
    "        value_new = int(value_new)\n",
    "        return value_new\n",
    "    except:\n",
    "        value_new = 0\n",
    "        return value_new\n",
    "\n",
    "# normalise the 'value' column\n",
    "df['clean_value'] = df['Value'].apply(normalise_value)\n",
    "\n",
    "# review transformation\n",
    "print(df['Value'][0], '\\n')\n",
    "print(df['clean_value'][0], '\\n')\n",
    "df['clean_value'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25949dda-b502-477a-bfcc-18578da985f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2004-12-31\n",
       "1        2004-12-31\n",
       "2        2004-12-31\n",
       "3        2004-12-31\n",
       "4        2004-12-31\n",
       "            ...    \n",
       "216925   2006-05-11\n",
       "216926   2006-05-11\n",
       "216927   2006-05-11\n",
       "216928   2006-05-11\n",
       "216929   2006-05-11\n",
       "Name: Air Date, Length: 216930, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pandas.to_datetime function to convert the 'Air Date' column to a datetime column.\n",
    "df['Air Date'] = pd.to_datetime(df['Air Date'])\n",
    "\n",
    "# review transformation\n",
    "df['Air Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73b31e-610f-469c-abde-acaa0dd68a05",
   "metadata": {},
   "source": [
    "## 4) Answers In Questions\n",
    "\n",
    "Provided by: [Dataquest.io](https://www.dataquest.io/)\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer can be used for a question.\n",
    "- How often questions are repeated.\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question. \n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. \n",
    "\n",
    "We'll start working on the first question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c1f476-8151-4ee9-a66b-fb8946043095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that takes in a row in jeopardy, and return the number of words in answer that contain words from the question.\n",
    "\n",
    "\n",
    "# Split the clean_answer column around spaces and assign to the variable split_answer.\n",
    "# Split the clean_question column around spaces and assign to the variable split_question.\n",
    "# remove 'the' in analysis as it is a common word and we are not interested\n",
    "# if no word in answer, return 0\n",
    "# add match_count incrementally for every answer word in question from same row\n",
    "\n",
    "def ans_in_qns_row(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    match_count = 0\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    if len(split_answer) == 0:\n",
    "        return None\n",
    "    for word in split_answer:\n",
    "        if word in row['clean_question']:\n",
    "            match_count += 1\n",
    "    ans_in_qns = match_count / len(split_answer)\n",
    "    return ans_in_qns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f84397-9b16-4728-b2e5-4522f5771f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000      2102\n",
       "0.888889         1\n",
       "0.875000         2\n",
       "0.857143         8\n",
       "0.833333         6\n",
       "0.818182         1\n",
       "0.800000        43\n",
       "0.777778         1\n",
       "0.750000       211\n",
       "0.714286        11\n",
       "0.700000         1\n",
       "0.692308         1\n",
       "0.666667      1834\n",
       "0.636364         1\n",
       "0.625000        12\n",
       "0.615385         1\n",
       "0.600000       177\n",
       "0.583333         1\n",
       "0.571429        22\n",
       "0.555556         6\n",
       "0.545455         4\n",
       "0.500000     20968\n",
       "0.466667         1\n",
       "0.454545         3\n",
       "0.444444         7\n",
       "0.428571        76\n",
       "0.400000       520\n",
       "0.384615         2\n",
       "0.375000        43\n",
       "0.368421         1\n",
       "0.363636         5\n",
       "0.357143         2\n",
       "0.350000         1\n",
       "0.333333      7823\n",
       "0.307692         1\n",
       "0.300000        11\n",
       "0.285714       145\n",
       "0.272727         7\n",
       "0.266667         2\n",
       "0.250000      2259\n",
       "0.230769         4\n",
       "0.222222        36\n",
       "0.214286         2\n",
       "0.200000       901\n",
       "0.181818         9\n",
       "0.166667       329\n",
       "0.153846         3\n",
       "0.142857       127\n",
       "0.125000        59\n",
       "0.111111        29\n",
       "0.100000        10\n",
       "0.090909         2\n",
       "0.083333         5\n",
       "0.076923         1\n",
       "0.071429         1\n",
       "0.066667         1\n",
       "0.058824         1\n",
       "0.000000    179070\n",
       "NaN             17\n",
       "Name: answer_in_question, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many times terms in clean_answer occur in clean_question\n",
    "\n",
    "df['answer_in_question'] = df.apply(ans_in_qns_row, axis=1)\n",
    "\n",
    "# review transformation\n",
    "df['answer_in_question'].value_counts(dropna=False).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68e059d-d235-4a37-9e3e-4e751607f141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08262726704616181"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute mean of the answer_in_question column\n",
    "df['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2e1c1-0232-4cb7-88bd-528947a5727e",
   "metadata": {},
   "source": [
    "#### Findings (Answers In Questions):\n",
    "\n",
    "The mean proportion of each word in answers that also appear in questions of the game is approximately 0.08.\n",
    "\n",
    "The interpretation is that the the likelihood is not high enough for us to explore further the strategy of using words contained in the question to increase our chance of guessing correctly at the answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f8220-31c1-431d-8fee-faa1dcde2c28",
   "metadata": {},
   "source": [
    "## 5) Recycled Questions\n",
    "\n",
    "Provided by: [Dataquest.io](https://www.dataquest.io/)\n",
    "\n",
    "Now we want to investigate how often new questions are repeats of older ones. \n",
    "\n",
    "Do note that we can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but it can be investigated at least.\n",
    "\n",
    "We can do this via the below:\n",
    "- sort dataset in order of ascending air date\n",
    "- Maintain a set called **terms_used** that will be empty initially.\n",
    "- Iterate through each row of dataset.\n",
    "- Split **clean_question** into words, remove any word shorter than 6 characters, and check if each word occurs in **terms_used**.\n",
    "    - If it does, increment a counter.\n",
    "    - Add each word to **terms_used**.\n",
    "    \n",
    "This allows us to check if the terms in questions have been used previously or not. Only looking at words with six or more characters enables to filter out words like the and than, which are commonly used, but don't tell alot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "252517fb-494b-4a20-ad40-ad913e95848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1984-09-10\n",
      "1   1984-09-10\n",
      "Name: Air Date, dtype: datetime64[ns]\n",
      "216928   2012-01-27\n",
      "216929   2012-01-27\n",
      "Name: Air Date, dtype: datetime64[ns] \n",
      "\n",
      "1984-09-10 00:00:00\n",
      "2012-01-27 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>answer_in_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>$100</td>\n",
       "      <td>River mentioned most often in the Bible</td>\n",
       "      <td>the Jordan</td>\n",
       "      <td>river mentioned most often in the bible</td>\n",
       "      <td>the jordan</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>THE BIBLE</td>\n",
       "      <td>$1000</td>\n",
       "      <td>According to 1st Timothy, it is the \"root of a...</td>\n",
       "      <td>the love of money</td>\n",
       "      <td>according to 1st timothy it is the root of all...</td>\n",
       "      <td>the love of money</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>'50'S TV</td>\n",
       "      <td>$1000</td>\n",
       "      <td>Name under which experimenter Don Herbert taug...</td>\n",
       "      <td>Mr. Wizard</td>\n",
       "      <td>name under which experimenter don herbert taug...</td>\n",
       "      <td>mr wizard</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>NATIONAL LANDMARKS</td>\n",
       "      <td>$1000</td>\n",
       "      <td>D.C. building shaken by November '83 bomb blast</td>\n",
       "      <td>the Capitol</td>\n",
       "      <td>dc building shaken by november 83 bomb blast</td>\n",
       "      <td>the capitol</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>NOTORIOUS</td>\n",
       "      <td>$1000</td>\n",
       "      <td>After the deed, he leaped to the stage shoutin...</td>\n",
       "      <td>John Wilkes Booth</td>\n",
       "      <td>after the deed he leaped to the stage shouting...</td>\n",
       "      <td>john wilkes booth</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>VISITING THE CITY</td>\n",
       "      <td>$800</td>\n",
       "      <td>There's a great opera house on Bennelong Point...</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>theres a great opera house on bennelong point ...</td>\n",
       "      <td>sydney</td>\n",
       "      <td>800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PANTS</td>\n",
       "      <td>$1,400</td>\n",
       "      <td>Tight-fitting pants patterned after those worn...</td>\n",
       "      <td>toreador pants</td>\n",
       "      <td>tightfitting pants patterned after those worn ...</td>\n",
       "      <td>toreador pants</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>CHILD ACTORS</td>\n",
       "      <td>$800</td>\n",
       "      <td>This kid, with a familiar last name, is seen &lt;...</td>\n",
       "      <td>Jaden Smith</td>\n",
       "      <td>this kid with a familiar last name is seen a h...</td>\n",
       "      <td>jaden smith</td>\n",
       "      <td>800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LESSER-KNOWN SCIENTISTS</td>\n",
       "      <td>$800</td>\n",
       "      <td>Joseph Lagrange insisted on 10 as the basic un...</td>\n",
       "      <td>the metric system</td>\n",
       "      <td>joseph lagrange insisted on 10 as the basic un...</td>\n",
       "      <td>the metric system</td>\n",
       "      <td>800</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PANTS</td>\n",
       "      <td>$200</td>\n",
       "      <td>A synonym for freight, or pants with large bel...</td>\n",
       "      <td>cargo pants</td>\n",
       "      <td>a synonym for freight or pants with large bell...</td>\n",
       "      <td>cargo pants</td>\n",
       "      <td>200</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Show Number   Air Date             Round                 Category  \\\n",
       "0                 1 1984-09-10         Jeopardy!           LAKES & RIVERS   \n",
       "1                 1 1984-09-10  Double Jeopardy!                THE BIBLE   \n",
       "2                 1 1984-09-10  Double Jeopardy!                 '50'S TV   \n",
       "3                 1 1984-09-10  Double Jeopardy!       NATIONAL LANDMARKS   \n",
       "4                 1 1984-09-10  Double Jeopardy!                NOTORIOUS   \n",
       "...             ...        ...               ...                      ...   \n",
       "216925         6300 2012-01-27         Jeopardy!        VISITING THE CITY   \n",
       "216926         6300 2012-01-27         Jeopardy!                    PANTS   \n",
       "216927         6300 2012-01-27         Jeopardy!             CHILD ACTORS   \n",
       "216928         6300 2012-01-27         Jeopardy!  LESSER-KNOWN SCIENTISTS   \n",
       "216929         6300 2012-01-27         Jeopardy!                    PANTS   \n",
       "\n",
       "         Value                                           Question  \\\n",
       "0         $100            River mentioned most often in the Bible   \n",
       "1        $1000  According to 1st Timothy, it is the \"root of a...   \n",
       "2        $1000  Name under which experimenter Don Herbert taug...   \n",
       "3        $1000    D.C. building shaken by November '83 bomb blast   \n",
       "4        $1000  After the deed, he leaped to the stage shoutin...   \n",
       "...        ...                                                ...   \n",
       "216925    $800  There's a great opera house on Bennelong Point...   \n",
       "216926  $1,400  Tight-fitting pants patterned after those worn...   \n",
       "216927    $800  This kid, with a familiar last name, is seen <...   \n",
       "216928    $800  Joseph Lagrange insisted on 10 as the basic un...   \n",
       "216929    $200  A synonym for freight, or pants with large bel...   \n",
       "\n",
       "                   Answer                                     clean_question  \\\n",
       "0              the Jordan            river mentioned most often in the bible   \n",
       "1       the love of money  according to 1st timothy it is the root of all...   \n",
       "2              Mr. Wizard  name under which experimenter don herbert taug...   \n",
       "3             the Capitol       dc building shaken by november 83 bomb blast   \n",
       "4       John Wilkes Booth  after the deed he leaped to the stage shouting...   \n",
       "...                   ...                                                ...   \n",
       "216925             Sydney  theres a great opera house on bennelong point ...   \n",
       "216926     toreador pants  tightfitting pants patterned after those worn ...   \n",
       "216927        Jaden Smith  this kid with a familiar last name is seen a h...   \n",
       "216928  the metric system  joseph lagrange insisted on 10 as the basic un...   \n",
       "216929        cargo pants  a synonym for freight or pants with large bell...   \n",
       "\n",
       "             clean_answer  clean_value  answer_in_question  \n",
       "0              the jordan          100            0.000000  \n",
       "1       the love of money         1000            0.333333  \n",
       "2               mr wizard         1000            0.000000  \n",
       "3             the capitol         1000            0.000000  \n",
       "4       john wilkes booth         1000            0.000000  \n",
       "...                   ...          ...                 ...  \n",
       "216925             sydney          800            0.000000  \n",
       "216926     toreador pants         1400            0.500000  \n",
       "216927        jaden smith          800            0.000000  \n",
       "216928  the metric system          800            0.500000  \n",
       "216929        cargo pants          200            0.500000  \n",
       "\n",
       "[216930 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate empty list\n",
    "question_overlap = []\n",
    "\n",
    "# initiate empty set\n",
    "terms_used = set()\n",
    "\n",
    "# sort dataset by ascending air date and reset index for data manipulation later\n",
    "df.sort_values(by='Air Date', axis=0, inplace=True, ascending=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# review transformation\n",
    "print(df['Air Date'].head(2))\n",
    "print(df['Air Date'].tail(2), '\\n')\n",
    "print(df['Air Date'].min())\n",
    "print(df['Air Date'].max())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a763dbc-4515-47af-82e4-3cc57e61e975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299470655337387"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the iterrows Dataframe method to loop through each row of dataset to review repeated words in questions\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # split over whitespace since unspecified argument\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    # loop each word in split_question\n",
    "    for word in split_question:\n",
    "        # remove any word with less than 6 char\n",
    "        if len(word) < 6:\n",
    "            split_question.remove(word)\n",
    "\n",
    "    # set match_count to zero\n",
    "    match_count = 0\n",
    "    \n",
    "    # loop each word in revised split_question\n",
    "    for word in split_question:\n",
    "        # increment match_count if word in qns is repeated in terms_used previously before the current question\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "\n",
    "        # Add each word in split_question to the set of terms_used\n",
    "        terms_used.add(word)\n",
    "    \n",
    "    if len(split_question) > 0:\n",
    "        match_count_proportion = match_count / len(split_question)\n",
    "    else:\n",
    "        match_count_proportion = None\n",
    "##     checking bugs        \n",
    "#     if match_count > len(split_question):\n",
    "#         print(index, split_question, match_count, len(split_question))\n",
    "    \n",
    "    question_overlap.append(match_count_proportion)    \n",
    "\n",
    "# assign the newly created list to new column (turn it into array before assigning)    \n",
    "df['question_overlap'] = np.array(question_overlap)\n",
    "\n",
    "# compute mean of question_overlap\n",
    "df['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0ec53e-d0be-4c08-8d96-cf572a6c42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000    135838\n",
      "0.970588         2\n",
      "0.969697         2\n",
      "0.968750         6\n",
      "0.967742         9\n",
      "             ...  \n",
      "0.142857        19\n",
      "0.125000        10\n",
      "0.111111         2\n",
      "0.000000      1032\n",
      "NaN            513\n",
      "Name: question_overlap, Length: 153, dtype: int64\n",
      "0.6749501183198114\n"
     ]
    }
   ],
   "source": [
    "# review distribution of question overlap columns\n",
    "print(df['question_overlap'].value_counts(dropna=False).sort_index(ascending=False))\n",
    "print((df['question_overlap'] == 1).sum() / df['question_overlap'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc3dbb-1612-4c48-9441-20615aa3a148",
   "metadata": {},
   "source": [
    "#### Findings (Recycled Questions):\n",
    "\n",
    "There do appear to have a high proportion of recycled questions (mean count of approximately 0.93). The interpretation is that there is a higher chance of success in the game by working out existing questions as questions tend to be repeated.\n",
    "\n",
    "In particularly, it would seems that 67% of the questions seem to be very similar to existing questions (evidenced by value of 1 among question overlap)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5600a-3a65-4f7c-b5c1-b52a28634446",
   "metadata": {},
   "source": [
    "## 6) Low Value VS High Value Questions\n",
    "\n",
    "Provided by: [Dataquest.io](https://www.dataquest.io/)\n",
    "\n",
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help to earn more money when playing Jeopardy.\n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test. We can first narrow down the questions into two categories:\n",
    "- Low value -- Any row where **Value** is less than **800**.\n",
    "- High value -- Any row where **Value** is greater than **800**.\n",
    "\n",
    "\n",
    "We would then be able to loop through each of the terms in the set we created previously, **'terms_used'**, and:\n",
    "- Find the number of low value questions the word occurs in.\n",
    "- Find the number of high value questions the word occurs in.\n",
    "- Find the percentage of questions the word occurs in.\n",
    "- Based on the percentage of questions the word occurs in, find expected counts.\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. \n",
    "\n",
    "Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e05430-e1dc-46bc-8f41-0a03a721686e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    155508\n",
       "1     61422\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function that takes in a row from a Dataframe and categorise between high/low value\n",
    "def categorise_value_row(row):\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "# Create new column - determine which questions are high and low value\n",
    "df['high_value'] = df.apply(categorise_value_row, axis=1)\n",
    "\n",
    "# review transformation\n",
    "df['high_value'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c768c9-8105-40ba-b6f5-d8f982a0b914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1),\n",
       " (1, 0),\n",
       " (0, 2),\n",
       " (1, 0),\n",
       " (15, 29),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function that takes in a word, then count number of times that word appeared in separate categories - high value or low value questions\n",
    "# Dataquest suggested using iterrows for this custom function, but do note that iterrows have performance issue (ie. slow), hence it would be preferable to perform vectorisation (most preferred) or df.apply functions whenever possible to optimise the execution speed and capacity\n",
    "def categorise_value_word(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # split over whitespace since unspecified argument\n",
    "        clean_question = row['clean_question'].split()\n",
    "        if word in clean_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1 \n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count  # returns a tuple\n",
    "\n",
    "\n",
    "# Randomly pick ten elements of terms_used and append them to a list 'comparison_terms'\n",
    "import random\n",
    "comparision_terms = random.sample(terms_used, 10)\n",
    "\n",
    "# initiate empty list - 'observed_expected'\n",
    "observed_expected = []\n",
    "\n",
    "# Loop through each term in 'comparison_terms' and get the high/low value count by executing the custom function, then append the result to the list - 'observed_expected'\n",
    "for word in comparision_terms:\n",
    "    observed_expected.append(categorise_value_word(word))\n",
    "\n",
    "# review transformation\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5f31a-b2df-471d-a69d-df247dbe6202",
   "metadata": {},
   "source": [
    "## 7) Applying The Chi-Squared Test\n",
    "\n",
    "Now that we have found the observed counts for a few terms, we can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1947087a-5805-4aab-a8aa-810a93706b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.08903022665047575,\n",
       " 0.09339047859424233,\n",
       " 0.4517393239670726,\n",
       " 0.09339047859424233,\n",
       " 0.017633404914900765,\n",
       " 0.09339047859424233,\n",
       " 0.5946491771067005,\n",
       " 0.5946491771067005,\n",
       " 0.5946491771067005,\n",
       " 0.09339047859424233]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proceed with computation of chi-square and p-value to apply the test\n",
    "\n",
    "# chisquare(observed, expected)\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "# no. of rows categorised as high value and low value\n",
    "high_value_count = df['high_value'].sum()\n",
    "low_value_count = len(df['high_value'] == 0)\n",
    "\n",
    "# initiate empty list\n",
    "chi_squared = []\n",
    "p_values = []\n",
    "\n",
    "# Loop through each tuple pair in observed_expected which is in format of (high_count, low_count)\n",
    "for tup in observed_expected:\n",
    "    total = sum(tup)  # get total count of high + low\n",
    "    total_prop = total / df.shape[0]  # get proportion for each word in comparision_terms for comparability between words (since each count means found in 1 row, hence proportion denominator is total number of rows in dataset)\n",
    "    expected_high_value_count = total_prop * high_value_count\n",
    "    expected_low_value_count = total_prop * low_value_count\n",
    "    \n",
    "    # since only 2 categories, ddof in function = 0\n",
    "    chisquare_value, pvalue = chisquare(tup, (expected_high_value_count, expected_low_value_count))\n",
    "    chi_squared.append(chisquare_value)\n",
    "    p_values.append(pvalue)\n",
    "                   \n",
    "# review chi-square and p-values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(chi_squared)\n",
    "plt.title('chi_square distribution for 10 sample comparision words')\n",
    "plt.show()\n",
    "plt.hist(p_values)\n",
    "plt.title('p_value distribution for 10 sample comparision words')\n",
    "plt.show()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029e2f3-8f49-4d3f-bf4c-91c4d8b669f4",
   "metadata": {},
   "source": [
    "#### Findings (Applying The Chi-Squared Test):\n",
    "\n",
    "The chi-squared test enables us to quantify the difference between sets of observed andexpected categorical values to determine statistical significance.\n",
    "\n",
    "A p-value allows us to determine whether the difference between 2 values is due to chance, or due to an underlying difference.\n",
    "\n",
    "0.05 p-value is the typical threshold for statistical significance, and anything below it is considered significant.\n",
    "\n",
    "Remember the purpose of performing the chi-squared test in this project exercise is to identify the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values (or low p-values).\n",
    "\n",
    "As such from our limited 10 samples, it would appear that most of the words do not have such distinction in statistical differences, though it can still be useful in focusing on those words that fulfill our criteria (high chi-squared values / low p-values), which can then be further investigated if it belongs mainly to high-value or low-value category, as a chi-squared test does not inform the direction of the classification.\n",
    "\n",
    "A larger sample size can also be conducted for production purposes to shortlist more candidates. However, the current code is slow when using df.iterrows(), hence see below conclusion for further discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e117c5-d2a9-41b7-b19b-7d9f50418ba8",
   "metadata": {},
   "source": [
    "## 8) Conclusion:\n",
    "\n",
    "Key skills applied:\n",
    "\n",
    "- Applied a chi-square test to identify if any significant statistical differences in categorial data scoped in project.\n",
    "    - Processing and preparing the data to get the components of the test, before applying the formula.\n",
    "\n",
    "Potential next steps:\n",
    "- Find a better way to eliminate non-informative words than just removing words that are less than 6 characters long. Some ideas:\n",
    "    - Manually create a list of words to remove, like the, than, etc.\n",
    "    - Find a list of stopwords to remove.\n",
    "    - Remove words that occur in more than a certain percentage (like 5%) of questions.\n",
    "\n",
    "\n",
    "- Perform the chi-squared test across more terms to see what terms have larger differences. This is hard to do currently because the code is slow, but here are some ideas:\n",
    "    - Use the apply method to make the code that calculates frequencies more efficient.\n",
    "    - Only select terms that have high frequencies across the dataset, and ignore the others. \n",
    "\n",
    "\n",
    "- Look more into the Category column and see if any interesting analysis can be done with it. Some ideas:\n",
    "    - See which categories appear the most often.\n",
    "    - Find the probability of each category appearing in each round.\n",
    "\n",
    "\n",
    "- Use the whole Jeopardy dataset instead of the subset we used in this project exercise.\n",
    "\n",
    "- Use phrases instead of single words when seeing if there's overlap between questions. Single words don't capture the whole context of the question well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa53d1-f82d-4ac7-892c-b373969cdf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
